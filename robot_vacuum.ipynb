{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *NOTE*\n",
    "- this is a resubmission of my original project due to the fact that my code takes such a long time to run that I wasn't able to submit my project in time for the first deadline, and run the portion of the code that would give the graph legitimate data. I am resubmitting it now that I finally have time, and as you can see here, none of my code from the original submission has changed (apart from one global variable included in the graph section). I am aware that this is way past the deadline, but I was hoping that you would be willing to take this submission as a candidate for an on-time submission of the project, as the only reason I was unable to submit one originally is the run time of my code. Either way, thank you for your time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PyOAq2XZ_soI"
   },
   "source": [
    "# Intelligent Agents: Reflex-Based Agents for the Vacuum-cleaner World\n",
    "\n",
    "Student Name: Rick Lattin\n",
    "\n",
    "## Instructions\n",
    "\n",
    "Total Points: Undergrads 100 / Graduate students 110\n",
    "\n",
    "Complete this notebook. Use the provided notebook cells and insert additional code and markdown cells as needed. Submit the completely rendered notebook as a PDF file.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this assignment you will implement a simulator environment for an automatic vacuum cleaner robot, a set of different reflex-based agent programs, and perform a comparison study for cleaning a single room. Focus on the __cleaning phase__ which starts when the robot is activated and ends when the last dirty square in the room has been cleaned. Someone else will take care of the agent program needed to navigate back to the charging station after the room is clean.\n",
    "\n",
    "## PEAS description of the cleaning phase\n",
    "\n",
    "__Performance Measure:__ Each action costs 1 energy unit. The performance is measured as the sum of the energy units used to clean the whole room.\n",
    "\n",
    "__Environment:__ A room with $n \\times n$ squares where $n = 5$. Dirt is randomly placed on each square with probability $p = 0.2$. For simplicity, you can assume that the agent knows the size and the layout of the room (i.e., it knows $n$). To start, the agent is placed on a random square.\n",
    "\n",
    "__Actuators:__ The agent can clean the current square (action `suck`) or move to an adjacent square by going `north`, `east`, `south`, or `west`.\n",
    "\n",
    "__Sensors:__ Four bumper sensors, one for north, east, south, and west; a dirt sensor reporting dirt in the current square.  \n",
    "\n",
    "\n",
    "## The agent program for a simple randomized agent\n",
    "\n",
    "The agent program is a function that gets sensor information (the current percepts) as the arguments. The arguments are:\n",
    "\n",
    "* A dictionary with boolean entries for the for bumper sensors `north`, `east`, `west`, `south`. E.g., if the agent is on the north-west corner, `bumpers` will be `{\"north\" : True, \"east\" : False, \"south\" : False, \"west\" : True}`.\n",
    "* The dirt sensor produces a boolean.\n",
    "\n",
    "The agent returns the chosen action as a string.\n",
    "\n",
    "Here is an example implementation for the agent program of a simple randomized agent:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Eh0T4U-4_soO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "actions = [\"north\", \"east\", \"west\", \"south\", \"suck\"]\n",
    "\n",
    "def simple_randomized_agent(bumpers, dirty):\n",
    "    return np.random.choice(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "duEyNuqn_soR",
    "outputId": "3646921b-8426-45c1-85d2-4f532068374d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'west'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define percepts (current location is NW corner and it is dirty)\n",
    "bumpers = {\"north\" : True, \"east\" : False, \"south\" : False, \"west\" : True}\n",
    "dirty = True\n",
    "\n",
    "# call agent program function with percepts and it returns an action\n",
    "simple_randomized_agent(bumpers, dirty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_m6q9n1_soS"
   },
   "source": [
    "__Note:__ This is not a rational intelligent agent. It ignores its sensors and may bump into a wall repeatedly or not clean a dirty square. You will be asked to implement rational agents below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_mmvtr0H_soT"
   },
   "source": [
    "## Simple environment example\n",
    "\n",
    "We implement a simple simulation environment that supplies the agent with its percepts.\n",
    "The simple environment is infinite in size (bumpers are always `False`) and every square is always dirty, even if the agent cleans it. The environment function returns a performance measure which is here the number of cleaned squares (since the room is infinite and all squares are constantly dirty, the agent can never clean the whole room as required in the PEAS description above). The energy budget of the agent is specified as `max_steps`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "J8yiqk8G_soT"
   },
   "outputs": [],
   "source": [
    "def simple_environment(agent, max_steps, verbose = True):\n",
    "    num_cleaned = 0\n",
    "\n",
    "    for i in range(max_steps):\n",
    "        dirty = True\n",
    "        bumpers = {\"north\" : False, \"south\" : False, \"west\" : False, \"east\" : False}\n",
    "\n",
    "        action = agent(bumpers, dirty)\n",
    "        if (verbose): print(\"step\", i , \"- action:\", action)\n",
    "\n",
    "        if (action == \"suck\"):\n",
    "            num_cleaned = num_cleaned + 1\n",
    "\n",
    "    return num_cleaned\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CDzybWyo_soU"
   },
   "source": [
    "Do one simulation run with a simple randomized agent that has enough energy for 20 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "dTNlu542_soU",
    "outputId": "987740fe-e409-44af-8f46-51f3ced6123b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 - action: north\n",
      "step 1 - action: north\n",
      "step 2 - action: south\n",
      "step 3 - action: north\n",
      "step 4 - action: suck\n",
      "step 5 - action: north\n",
      "step 6 - action: suck\n",
      "step 7 - action: suck\n",
      "step 8 - action: west\n",
      "step 9 - action: north\n",
      "step 10 - action: south\n",
      "step 11 - action: north\n",
      "step 12 - action: north\n",
      "step 13 - action: east\n",
      "step 14 - action: suck\n",
      "step 15 - action: north\n",
      "step 16 - action: north\n",
      "step 17 - action: suck\n",
      "step 18 - action: south\n",
      "step 19 - action: south\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_environment(simple_randomized_agent, max_steps = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWPgCTva_soV"
   },
   "source": [
    "# Tasks\n",
    "\n",
    "## General [10 Points]\n",
    "\n",
    "1. Make sure that you use the latest version of this notebook. Sync your forked repository and pull the latest revision.\n",
    "2. Your implementation can use libraries like math, numpy, scipy, but not libraries that implement inteligent agents or complete search algorithms. Try to keep the code simple! In this course, we want to learn about the algorithms and we often do not need to use object-oriented design.\n",
    "3. You notebook needs to be formated professionally.\n",
    "    - Add additional markdown blocks for your description, comments in the code, add tables and use mathplotlib to produce charts where appropriate\n",
    "    - Do not show debugging output or include an excessive amount of output.\n",
    "    - Check that your PDF file is readable. For example, long lines are cut off in the PDF file. You don't have control over page breaks, so do not worry about these.\n",
    "4. Document your code. Add a short discussion of how your implementation works and your design choices.\n",
    "\n",
    "\n",
    "## Task 1: Implement a simulation environment [20 Points]\n",
    "\n",
    "The simple environment above is not very realistic. Your environment simulator needs to follow the PEAS description from above. It needs to:\n",
    "\n",
    "* Initialize the environment by storing the state of each square (clean/dirty) and making some dirty. ([Help with random numbers and arrays in Python](https://github.com/mhahsler/CS7320-AI/blob/master/HOWTOs/random_numbers_and_arrays.ipynb))\n",
    "* Keep track of the agent's position.\n",
    "* Call the agent function repeatedly and provide the agent function with the sensor inputs.  \n",
    "* React to the agent's actions. E.g, by removing dirt from a square or moving the agent around unless there is a wall in the way.\n",
    "* Keep track of the performance measure. That is, track the agent's actions until all dirty squares are clean and count the number of actions it takes the agent to complete the task.\n",
    "\n",
    "The easiest implementation for the environment is to hold an 2-dimensional array to represent if squares are clean or dirty and to call the agent function in a loop until all squares are clean or a predefined number of steps have been reached (i.e., the robot runs out of energy).\n",
    "\n",
    "The simulation environment should be a function like the `simple_environment()` and needs to work with the simple randomized agent program from above. **Use the same environmnt for all your agent implementations in the tasks below.**\n",
    "\n",
    "*Note on debugging:* Debugging is difficult. Make sure your environment prints enough information when you use `verbose = True`. Also, implementing a function that the environment can use to displays the room with dirt and the current position of the robot at every step is very useful.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The environment begins by creating a square grid the the size of the size varibale passed in, and then filling 20% of those squares with dirt that is to be cleaned and filling the num_dirty variable with the number of dirtied squares. The clean squares are denoted with 0's and the dirty ones 1's. It then assigns a random starting location to the agent calling a loop that calls the agent, which has been passed in as a variable, an indefinite amount of times. The environment updates the bumper and dirty information before calling the agent, and then depending on the return of the agent, the environment will either move the agent north, south, east, or west, while also possibly performing the suck action. If the square the agent is currently, which is information saved by the environment, and the suck action is called, then the 1 is turned to a 0 on the grid. For each square cleaned the num_dirty variable is decremented and for each call of the agent, the num_steps variable is incremented. The environment finishes running when the max steps is reached or if the num_dirty variable reaches 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Smy-6KEu_soV"
   },
   "outputs": [],
   "source": [
    "# Your code and description goes here\n",
    "\n",
    "reached_corner = False \n",
    "last_move = \"north\"\n",
    "\n",
    "def vacuum_environment(agent, max_steps, size, verbose = True):\n",
    "    num_steps = 0\n",
    "    num_dirty = 0\n",
    "    agent_start_location = (0,0)\n",
    "    agent_location = (agent_start_location[0], agent_start_location[1])\n",
    "    reached_corner = False\n",
    "\n",
    "    #create the environment\n",
    "    grid = np.zeros((size,size))\n",
    "    for i in range(size):\n",
    "        for j in range(size):\n",
    "            if np.random.random() < 0.2:\n",
    "                grid[i,j] = 1\n",
    "                num_dirty += 1\n",
    "    if verbose == True:\n",
    "        print(grid)\n",
    "    \n",
    "    #make start point for agent\n",
    "    x_start = np.random.randint(0,size)\n",
    "    y_start = np.random.randint(0,size)\n",
    "    agent_start_location = (x_start,y_start)\n",
    "    agent_location = agent_start_location\n",
    "\n",
    "\n",
    "    for i in range(max_steps):\n",
    "\n",
    "        #send agent drity square information\n",
    "        if grid[agent_location[0], agent_location[1]] == 1:\n",
    "            dirty = True\n",
    "        else:\n",
    "            dirty = False\n",
    "        \n",
    "        #send agent bumpers information\n",
    "        bumpers = {\"north\" : False, \"south\" : False, \"west\" : False, \"east\" : False}\n",
    "        if verbose == True:\n",
    "            print(agent_location)\n",
    "        if agent_location[0] == 0:\n",
    "            bumpers[\"north\"] = True\n",
    "        if agent_location[0] == size-1:\n",
    "            bumpers[\"south\"] = True\n",
    "        if agent_location[1] == 0:\n",
    "            bumpers[\"west\"] = True\n",
    "        if agent_location[1] == size-1:\n",
    "            bumpers[\"east\"] = True\n",
    "\n",
    "        #call agent action\n",
    "        action = agent(bumpers, dirty)\n",
    "        if (verbose): print(\"step\", i , \"- action:\", action)\n",
    "\n",
    "        #making sure simple random doesn't break\n",
    "        if action == \"north\" and bumpers[\"north\"] == True:\n",
    "            action = \"none\"\n",
    "            num_steps += 1\n",
    "        if action == \"south\" and bumpers[\"south\"] == True:\n",
    "            action = \"none\"\n",
    "            num_steps += 1\n",
    "        if action == \"east\" and bumpers[\"east\"] == True:\n",
    "            action = \"none\"\n",
    "            num_steps += 1\n",
    "        if action == \"west\" and bumpers[\"west\"] == True:\n",
    "            action = \"none\"\n",
    "            num_steps += 1\n",
    "\n",
    "\n",
    "        #counting the steps\n",
    "        if (action == \"north\"):\n",
    "            agent_location = (agent_location[0]-1,agent_location[1])\n",
    "            num_steps += 1\n",
    "        if (action == \"east\"):\n",
    "            agent_location = (agent_location[0],agent_location[1]+1)\n",
    "            num_steps += 1\n",
    "        if (action == \"west\"):\n",
    "            agent_location = (agent_location[0],agent_location[1]-1)\n",
    "            num_steps += 1\n",
    "        if (action == \"south\"):\n",
    "            agent_location = (agent_location[0]+1,agent_location[1])\n",
    "            num_steps += 1\n",
    "\n",
    "        if (action == \"suck\"):\n",
    "            if grid[agent_location[0], agent_location[1]] == 1:\n",
    "                num_dirty = num_dirty - 1\n",
    "            num_steps += 1 \n",
    "            grid[agent_location[0], agent_location[1]] = 0\n",
    "\n",
    "        if num_dirty == 0:\n",
    "            break\n",
    "\n",
    "    if verbose == True:\n",
    "        print(grid)\n",
    "    return num_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1013304"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vacuum_environment(simple_randomized_agent, max_steps = 10000000, size = 100, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vulQTni9_soW"
   },
   "source": [
    "## Task 2:  Implement a simple reflex agent [10 Points]\n",
    "\n",
    "The simple reflex agent randomly walks around but reacts to the bumper sensor by not bumping into the wall and to dirt with sucking. Implement the agent program as a function.\n",
    "\n",
    "_Note:_ Agents cannot directly use variable in the environment. They only gets the percepts as the arguments to the agent function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This agent functionally works the same way as the simple randomized agent, with the only differences being that if the square the agent is on is seen to be dirty then the agent will automatically return the \"suck\" action and will refuse to return an action that is physically impossible based off of the bumpers. This streamlines the agent's cleaning process by allowing the agent to simply find the location of a dirty space in order to clean it. Furthermore, it prevents the agent from taking a move to attempt to move into a wall, which the simple randomized agent had the capacity to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "i7w06T3S_soW"
   },
   "outputs": [],
   "source": [
    "# Your code and description goes here\n",
    "import numpy as np\n",
    "\n",
    "actions = [\"north\", \"east\", \"west\", \"south\", \"suck\"]\n",
    "\n",
    "def simple_reflex_agent(bumpers, dirty):\n",
    "    #if dirty then clean\n",
    "    i = 1\n",
    "    if dirty == True:\n",
    "        return \"suck\"\n",
    "    else:\n",
    "        #if not dirty then move in a possible direction\n",
    "        while i == 1:\n",
    "            action = np.random.choice(actions)\n",
    "            if (action == \"suck\") or (bumpers[action] == True):\n",
    "                i = 1\n",
    "            else:\n",
    "                i = 0\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vacuum_environment(simple_reflex_agent, max_steps = 1000, size = 5, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BntpNDSM_soX"
   },
   "source": [
    "## Task 3: Implement a model-based reflex agent [20 Points]\n",
    "\n",
    "Model-based agents use a state to keep track of what they have done and perceived so far. Your agent needs to find out where it is located and then keep track of its current location. You also need a set of rules based on the state and the percepts to make sure that the agent will clean the whole room. For example, the agent can move to a corner to determine its location and then it can navigate through the whole room and clean dirty squares.\n",
    "\n",
    "Describe how you define the __agent state__ and how your agent works before implementing it. ([Help with implementing state information on Python](https://github.com/mhahsler/CS7320-AI/blob/master/HOWTOs/store_agent_state_information.ipynb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "LDm4JIMH_soX"
   },
   "outputs": [],
   "source": [
    "# Your short description of the state and your implementation goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The state that the agent retains is comprised of two data members. The first is a boolean value detailing whether the agent has reached the top left corner of the environment, as that is a necessary starting point of this implementation. The second is a string that represents the direction of the last move taken by the agent. The agent uses these two members in it's implemetation to first move itself to the top left corner of the environment, using the bumpers to find a location where both the \"north\" and \"west\" bumpers were triggered, which only exists in the top left corner. From there the reached_corner boolean is turned to \"True\" and the agent begins it's snaking functionality to hit every square in the environment. The agent first checks if the current square it is located in is dirty and cleans it axcordingly, then it continues to move in the direction it was previously moving by using the last_move string variable. The agent starts moving east then uses the bumpers to determine when it should turn and when it should end the snaking process as it has reached the end of the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "TN9Efq4t_soY"
   },
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "import numpy as np\n",
    "\n",
    "actions = [\"north\", \"east\", \"west\", \"south\", \"suck\"]\n",
    "reached_corner = False \n",
    "last_move = \"north\"\n",
    "\n",
    "def model_based_reflex_agent(bumpers, dirty):\n",
    "\n",
    "    #setting to top left corner\n",
    "    global reached_corner\n",
    "    global last_move\n",
    "    if reached_corner == False:\n",
    "        if bumpers[\"north\"] == True and bumpers[\"west\"] == True:\n",
    "            reached_corner = True\n",
    "        if bumpers[\"north\"] == False:\n",
    "            return \"north\"\n",
    "        if bumpers[\"west\"] == False:\n",
    "            return \"west\"\n",
    "\n",
    "    #if dirty then clean\n",
    "    if dirty == True:\n",
    "        return \"suck\"\n",
    "    \n",
    "    #starting move\n",
    "    if bumpers[\"west\"] == True and bumpers[\"north\"] == True:\n",
    "        last_move = \"east\"\n",
    "        return \"east\"\n",
    "    \n",
    "    #general movement\n",
    "    if bumpers[\"west\"] == True and last_move != \"south\":\n",
    "        last_move = \"south\"\n",
    "        return \"south\"\n",
    "    if bumpers[\"west\"] == True and last_move == \"south\":\n",
    "        last_move = \"east\"\n",
    "        return \"east\"\n",
    "    if bumpers[\"east\"] == True and last_move != \"south\":\n",
    "        last_move = \"south\"\n",
    "        return \"south\"\n",
    "    if bumpers[\"east\"] == True and last_move == \"south\":\n",
    "        last_move = \"west\"\n",
    "        return \"west\"\n",
    "    else:\n",
    "        return last_move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reached_corner = False \n",
    "last_move = \"north\"\n",
    "\n",
    "vacuum_environment(model_based_reflex_agent, max_steps = 1000, size = 5, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sL3JzC0U_soZ"
   },
   "source": [
    "## Task 4: Simulation study [30 Points]\n",
    "\n",
    "Compare the performance (the performance measure is defined in the PEAS description above) of the agents using  environments of different size. E.g., $5 \\times 5$, $10 \\times 10$ and\n",
    "$100 \\times 100$. Use 100 random runs for each. Present the results using tables and graphs. Discuss the differences between the agents.\n",
    "([Help with charts and tables in Python](https://github.com/mhahsler/CS7320-AI/blob/master/HOWTOs/charts_and_tables.ipynb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "NI4vM-RH_soa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size</th>\n",
       "      <th>Simple Randomized Agent</th>\n",
       "      <th>Simple Reflex Agent</th>\n",
       "      <th>Model Based Reflex Agent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5x5</td>\n",
       "      <td>432.69</td>\n",
       "      <td>101.40</td>\n",
       "      <td>28.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10x10</td>\n",
       "      <td>2935.22</td>\n",
       "      <td>869.22</td>\n",
       "      <td>124.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100x100</td>\n",
       "      <td>830867.55</td>\n",
       "      <td>337124.63</td>\n",
       "      <td>12093.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Size  Simple Randomized Agent  Simple Reflex Agent  \\\n",
       "0      5x5                   432.69               101.40   \n",
       "1    10x10                  2935.22               869.22   \n",
       "2  100x100                830867.55            337124.63   \n",
       "\n",
       "   Model Based Reflex Agent  \n",
       "0                     28.35  \n",
       "1                    124.30  \n",
       "2                  12093.64  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code goes here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "all_size = [5, 10, 100]\n",
    "myDF = pd.DataFrame({})\n",
    "\n",
    "# making table\n",
    "df = pd.DataFrame({\n",
    "    \"Size\": [\"5x5\", \"10x10\", \"100x100\"],\n",
    "    \"Simple Randomized Agent\": np.zeros(3),\n",
    "    \"Simple Reflex Agent\": np.zeros(3),\n",
    "    \"Model Based Reflex Agent\": np.zeros(3)\n",
    "})\n",
    "\n",
    "# testing for each size\n",
    "#for one_size in all_size:\n",
    "for one_size in all_size:\n",
    "    simple_randomized_data = []\n",
    "    simple_reflex_data = []\n",
    "    model_based_reflex_data = []\n",
    "    \n",
    "    for i in range(100):\n",
    "        simple_randomized_data.append(vacuum_environment(simple_randomized_agent, max_steps = 10000000, size = one_size, verbose = False))\n",
    "        simple_reflex_data.append(vacuum_environment(simple_reflex_agent, max_steps = 1000000, size = one_size, verbose = False))\n",
    "\n",
    "        reached_corner = False \n",
    "        last_move = \"north\" \n",
    "        model_based_reflex_data.append(vacuum_environment(model_based_reflex_agent, max_steps = 100000, size = one_size, verbose = False))\n",
    "\n",
    "    # adding to table\n",
    "    df.loc[df[\"Size\"] == str(one_size)+\"x\"+str(one_size), \"Simple Randomized Agent\"] = np.mean(simple_randomized_data)\n",
    "    df.loc[df[\"Size\"] == str(one_size)+\"x\"+str(one_size), \"Simple Reflex Agent\"] = np.mean(simple_reflex_data)\n",
    "    df.loc[df[\"Size\"] == str(one_size)+\"x\"+str(one_size), \"Model Based Reflex Agent\"] = np.mean(model_based_reflex_data)\n",
    "\n",
    "myDF = df\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RCluPvy9_soa"
   },
   "source": [
    "Fill out the following table with the average performance measure for 100 random runs (you may also create this table with code):\n",
    "\n",
    "| Size     | Randomized Agent | Simple Reflex Agent | Model-based Reflex Agent |\n",
    "|----------|------------------|---------------------|--------------------------|\n",
    "| 5x5     | | | |\n",
    "| 10x10   | | | |\n",
    "| 100x100 | | | |\n",
    "\n",
    "Add charts to compare the performance of the different agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "b5z5JjRO_sob"
   },
   "outputs": [],
   "source": [
    "# Your graphs and discussion of the results goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The three agents were compared by running each one 100 times each, for the 5x5 environment, the 10x10 environment and the 100x100 environment, with the only variable changing between each of the 100 runs being the size of the max steps assigned to each. The modal based reflex agent was given a max steps of 100,000, as it would take 10,000 steps alone to check every space on the 100x100 environment, so it was decided to multiply by 10 for that to accound for the other operations it would have to complete. The simple reflex based agent was give a max steps of 1,000,000 as it was 10 times more than the modal based agent and the simple randomized agent was given 10,000,000 as it was 10 times the simle reflex agent.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size</th>\n",
       "      <th>Simple Randomized Agent</th>\n",
       "      <th>Simple Reflex Agent</th>\n",
       "      <th>Model Based Reflex Agent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5x5</td>\n",
       "      <td>432.69</td>\n",
       "      <td>101.40</td>\n",
       "      <td>28.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10x10</td>\n",
       "      <td>2935.22</td>\n",
       "      <td>869.22</td>\n",
       "      <td>124.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100x100</td>\n",
       "      <td>830867.55</td>\n",
       "      <td>337124.63</td>\n",
       "      <td>12093.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Size  Simple Randomized Agent  Simple Reflex Agent  \\\n",
       "0      5x5                   432.69               101.40   \n",
       "1    10x10                  2935.22               869.22   \n",
       "2  100x100                830867.55            337124.63   \n",
       "\n",
       "   Model Based Reflex Agent  \n",
       "0                     28.35  \n",
       "1                    124.30  \n",
       "2                  12093.64  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(myDF[\"Size\"], myDF[\"Simple Randomized Agent\"], label = \"Simple Randomized Agent\")\n",
    "plt.plot(myDF[\"Size\"], myDF[\"Simple Reflex Agent\"], label = \"Simple Reflex Agent\")\n",
    "plt.plot(myDF[\"Size\"], myDF[\"Model Based Reflex Agent\"], label = \"Model Based Reflex Agent\")\n",
    "plt.xlabel(\"Environment Dimensions\")\n",
    "plt.ylabel(\"Performance of the agents\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "myDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This graph displays the relationship between each model and the time it took each to run based off of their respective sizes. Through this graph it can be easily seen that the Modal based agent is easily the most efficient in completing the task of cleaning the environment and the simple randomized agent was the least efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uxu1djsV_sob"
   },
   "source": [
    "## Task 5: Robustness of the agent implementations [10 Points]\n",
    "\n",
    "Describe how **your agent implementations** will perform\n",
    "\n",
    "* if it is put into a rectangular room with unknown size,\n",
    "* if the cleaning area can have an iregular shape (e.g., a hallway connecting two rooms), or\n",
    "* if the room contains obstacles (i.e., squares that it cannot pass through and trigger the bumper sensors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Hf9QCIYB_sob"
   },
   "outputs": [],
   "source": [
    "# Answer goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### \n",
    "- The agent implementation would still work effectivley in a rectangular room with an unknown size, as the size of the room is not taken as a paramter in the agent function, and the fact that it is squared is not used as a factor in the original environment. The only thing that is used as a necessary given, is the fact that the environment has four right angle corners, which a rectangle has as well.\n",
    "\n",
    "- The agent implementation would not be able to effectivley function if the room was an irregular shape, as the implementation relies on the fact that the environment will be able to access the top left corner of the environment from purely going up until a \"north\" bumper is hit, and then going left until a \"west\" bumper is hit, as well as using this corner as a starting point for snaking through the rest of the environment. Therefore, if the agent is in an environment where there is more than one top-left corner, such as a hallway connecting two rooms, then it would be for the agent to iterate over every space in the environment.\n",
    "\n",
    "- The agent implementation would not be able to effectivley function if the room contained obstacles either, as the obstacles to turn before hitting the wall of the room in some cases, causing the agent to effectivley miss portions of the room and possibly leave areas uncleaned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QeRyAO9K_soc"
   },
   "source": [
    "## Graduate student advanced task: Obstacles [10 Points]\n",
    "\n",
    "__Undergraduate students:__ This is a bonus task you can attempt if you like [+5 Bonus Points].\n",
    "\n",
    "1. Change your simulation environment tor run experiments for the following problem: Add random obstacle squares that also trigger the bumper sensor. The agent does not know where the obstacles are. Observe how this changes the performance of the three implementations.\n",
    "\n",
    "2. Describe what would need to be done to perform better with obstacles. Add code if you can."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###\n",
    "1. The changes observed were that, for the the simple reflex agent and the modal based reflex agent, there were instances when cleaning the 10x10 and 100x100 where the environment simply never got cleaned. \n",
    "\n",
    "2. Assuming that the robot could reach every square in the environment, the primary thing that would need to be done is to have the agent keep track of the number of steps done during one row of the snaking process, and compare it to the next row. As soon as one row has a different length traveled before turning, if it is less than the previous then the agent will investigate what was previously percieved as wall on the current row to see if it is possible to travel past thenm on either side, and if the distance is more than the previous row then the same investigation will be done on the row prior. If there is determined to be an obstacle in the row then the agent will attempt to go around it and adjust the length of the row accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "N_piAjcU_soc"
   },
   "outputs": [],
   "source": [
    "# Your code and discussion goes here\n",
    "\n",
    "reached_corner = False \n",
    "last_move = \"north\"\n",
    "\n",
    "def obstacle_environment(agent, max_steps, size, verbose = True):\n",
    "    num_steps = 0\n",
    "    num_dirty = 0\n",
    "    agent_start_location = (0,0)\n",
    "    agent_location = (agent_start_location[0], agent_start_location[1])\n",
    "\n",
    "    #create the environment\n",
    "    grid = np.zeros((size,size))\n",
    "    for i in range(size):\n",
    "        for j in range(size):\n",
    "            randNum = np.random.random()\n",
    "            if randNum < 0.2:\n",
    "                grid[i,j] = 1\n",
    "                num_dirty += 1\n",
    "            if randNum > 0.8:\n",
    "                grid[i,j] = 2\n",
    "    if verbose == True:\n",
    "        print(grid)\n",
    "    \n",
    "    #make start point for agent\n",
    "    x_start = np.random.randint(0,size)\n",
    "    y_start = np.random.randint(0,size)\n",
    "    agent_start_location = (x_start,y_start)\n",
    "    agent_location = agent_start_location\n",
    "\n",
    "\n",
    "    for i in range(max_steps):\n",
    "\n",
    "        #send agent drity square information\n",
    "        if grid[agent_location[0], agent_location[1]] == 1:\n",
    "            dirty = True\n",
    "        else:\n",
    "            dirty = False\n",
    "        \n",
    "        #send agent bumpers information\n",
    "        bumpers = {\"north\" : False, \"south\" : False, \"west\" : False, \"east\" : False}\n",
    "        if verbose == True:\n",
    "            print(agent_location)\n",
    "        if agent_location[0] == 0:\n",
    "            bumpers[\"north\"] = True\n",
    "        if agent_location[0] == size-1:\n",
    "            bumpers[\"south\"] = True\n",
    "        if agent_location[1] == 0:\n",
    "            bumpers[\"west\"] = True\n",
    "        if agent_location[1] == size-1:\n",
    "            bumpers[\"east\"] = True\n",
    "\n",
    "        #send agent barrier information regarding bumpers \n",
    "        if bumpers[\"north\"] == False:\n",
    "            if grid[agent_location[0]-1, agent_location[1]] == 2:\n",
    "                bumpers[\"north\"] = True\n",
    "        if bumpers[\"south\"] == False:\n",
    "            if grid[agent_location[0]+1, agent_location[1]] == 2:\n",
    "                bumpers[\"south\"] = True\n",
    "        if bumpers[\"west\"] == False:\n",
    "            if grid[agent_location[0], agent_location[1]-1] == 2:\n",
    "                bumpers[\"west\"] = True\n",
    "        if bumpers[\"east\"] == False:\n",
    "            if grid[agent_location[0], agent_location[1]+1] == 2:\n",
    "                bumpers[\"east\"] = True\n",
    "\n",
    "        #call agent action\n",
    "        action = agent(bumpers, dirty)\n",
    "        if (verbose): print(\"step\", i , \"- action:\", action)\n",
    "\n",
    "        #making sure simple random doesn't break\n",
    "        if action == \"north\" and bumpers[\"north\"] == True:\n",
    "            action = \"none\"\n",
    "        if action == \"south\" and bumpers[\"south\"] == True:\n",
    "            action = \"none\"\n",
    "        if action == \"east\" and bumpers[\"east\"] == True:\n",
    "            action = \"none\"\n",
    "        if action == \"west\" and bumpers[\"west\"] == True:\n",
    "            action = \"none\"\n",
    "\n",
    "\n",
    "        #counting the steps\n",
    "        if (action == \"north\"):\n",
    "            agent_location = (agent_location[0]-1,agent_location[1])\n",
    "            num_steps += 1\n",
    "        if (action == \"east\"):\n",
    "            agent_location = (agent_location[0],agent_location[1]+1)\n",
    "            num_steps += 1\n",
    "        if (action == \"west\"):\n",
    "            agent_location = (agent_location[0],agent_location[1]-1)\n",
    "            num_steps += 1\n",
    "        if (action == \"south\"):\n",
    "            agent_location = (agent_location[0]+1,agent_location[1])\n",
    "            num_steps += 1\n",
    "\n",
    "        if (action == \"suck\"):\n",
    "            num_dirty = num_dirty - 1\n",
    "            num_steps += 1 \n",
    "            grid[agent_location[0], agent_location[1]] = 0\n",
    "\n",
    "        if num_dirty == 0:\n",
    "            break\n",
    "\n",
    "    if verbose == True:\n",
    "        print(grid)\n",
    "    return num_steps\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size</th>\n",
       "      <th>Simple Randomized Agent</th>\n",
       "      <th>Simple Reflex Agent</th>\n",
       "      <th>Model Based Reflex Agent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5x5</td>\n",
       "      <td>14.8</td>\n",
       "      <td>98.6</td>\n",
       "      <td>25004.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10x10</td>\n",
       "      <td>75.6</td>\n",
       "      <td>200919.8</td>\n",
       "      <td>54509.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100x100</td>\n",
       "      <td>8402.0</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>16055.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Size  Simple Randomized Agent  Simple Reflex Agent  \\\n",
       "0      5x5                     14.8                 98.6   \n",
       "1    10x10                     75.6             200919.8   \n",
       "2  100x100                   8402.0            1000000.0   \n",
       "\n",
       "   Model Based Reflex Agent  \n",
       "0                   25004.8  \n",
       "1                   54509.0  \n",
       "2                   16055.2  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simulating with new environment\n",
    "\n",
    "# making table\n",
    "df = pd.DataFrame({\n",
    "    \"Size\": [\"5x5\", \"10x10\", \"100x100\"],\n",
    "    \"Simple Randomized Agent\": np.zeros(3),\n",
    "    \"Simple Reflex Agent\": np.zeros(3),\n",
    "    \"Model Based Reflex Agent\": np.zeros(3)\n",
    "})\n",
    "\n",
    "# testing for each size\n",
    "#for one_size in all_size:\n",
    "for one_size in all_size:\n",
    "    simple_randomized_data = []\n",
    "    simple_reflex_data = []\n",
    "    model_based_reflex_data = []\n",
    "    \n",
    "    for i in range(5):\n",
    "        simple_randomized_data.append(obstacle_environment(simple_randomized_agent, max_steps = 10000000, size = one_size, verbose = False))\n",
    "        simple_reflex_data.append(obstacle_environment(simple_reflex_agent, max_steps = 1000000, size = one_size, verbose = False))\n",
    "\n",
    "        reached_corner = False \n",
    "        last_move = \"north\" \n",
    "        model_based_reflex_data.append(obstacle_environment(model_based_reflex_agent, max_steps = 100000, size = one_size, verbose = False))\n",
    "\n",
    "    # adding to table\n",
    "    df.loc[df[\"Size\"] == str(one_size)+\"x\"+str(one_size), \"Simple Randomized Agent\"] = np.mean(simple_randomized_data)\n",
    "    df.loc[df[\"Size\"] == str(one_size)+\"x\"+str(one_size), \"Simple Reflex Agent\"] = np.mean(simple_reflex_data)\n",
    "    df.loc[df[\"Size\"] == str(one_size)+\"x\"+str(one_size), \"Model Based Reflex Agent\"] = np.mean(model_based_reflex_data)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same model but returning number of spaces left dirty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reached_corner = False \n",
    "last_move = \"north\"\n",
    "\n",
    "def obstacle_environment_dirty(agent, max_steps, size, verbose = True):\n",
    "    num_steps = 0\n",
    "    num_dirty = 0\n",
    "    agent_start_location = (0,0)\n",
    "    agent_location = (agent_start_location[0], agent_start_location[1])\n",
    "\n",
    "    #create the environment\n",
    "    grid = np.zeros((size,size))\n",
    "    for i in range(size):\n",
    "        for j in range(size):\n",
    "            randNum = np.random.random()\n",
    "            if randNum < 0.2:\n",
    "                grid[i,j] = 1\n",
    "                num_dirty += 1\n",
    "            if randNum > 0.8:\n",
    "                grid[i,j] = 2\n",
    "    if verbose == True:\n",
    "        print(grid)\n",
    "    \n",
    "    #make start point for agent\n",
    "    x_start = np.random.randint(0,size)\n",
    "    y_start = np.random.randint(0,size)\n",
    "    agent_start_location = (x_start,y_start)\n",
    "    agent_location = agent_start_location\n",
    "\n",
    "\n",
    "    for i in range(max_steps):\n",
    "\n",
    "        #send agent drity square information\n",
    "        if grid[agent_location[0], agent_location[1]] == 1:\n",
    "            dirty = True\n",
    "        else:\n",
    "            dirty = False\n",
    "        \n",
    "        #send agent bumpers information\n",
    "        bumpers = {\"north\" : False, \"south\" : False, \"west\" : False, \"east\" : False}\n",
    "        if verbose == True:\n",
    "            print(agent_location)\n",
    "        if agent_location[0] == 0:\n",
    "            bumpers[\"north\"] = True\n",
    "        if agent_location[0] == size-1:\n",
    "            bumpers[\"south\"] = True\n",
    "        if agent_location[1] == 0:\n",
    "            bumpers[\"west\"] = True\n",
    "        if agent_location[1] == size-1:\n",
    "            bumpers[\"east\"] = True\n",
    "\n",
    "        #send agent barrier information regarding bumpers \n",
    "        if bumpers[\"north\"] == False:\n",
    "            if grid[agent_location[0]-1, agent_location[1]] == 2:\n",
    "                bumpers[\"north\"] = True\n",
    "        if bumpers[\"south\"] == False:\n",
    "            if grid[agent_location[0]+1, agent_location[1]] == 2:\n",
    "                bumpers[\"south\"] = True\n",
    "        if bumpers[\"west\"] == False:\n",
    "            if grid[agent_location[0], agent_location[1]-1] == 2:\n",
    "                bumpers[\"west\"] = True\n",
    "        if bumpers[\"east\"] == False:\n",
    "            if grid[agent_location[0], agent_location[1]+1] == 2:\n",
    "                bumpers[\"east\"] = True\n",
    "\n",
    "        #call agent action\n",
    "        action = agent(bumpers, dirty)\n",
    "        if (verbose): print(\"step\", i , \"- action:\", action)\n",
    "\n",
    "        #making sure simple random doesn't break\n",
    "        if action == \"north\" and bumpers[\"north\"] == True:\n",
    "            action = \"none\"\n",
    "        if action == \"south\" and bumpers[\"south\"] == True:\n",
    "            action = \"none\"\n",
    "        if action == \"east\" and bumpers[\"east\"] == True:\n",
    "            action = \"none\"\n",
    "        if action == \"west\" and bumpers[\"west\"] == True:\n",
    "            action = \"none\"\n",
    "\n",
    "\n",
    "        #counting the steps\n",
    "        if (action == \"north\"):\n",
    "            agent_location = (agent_location[0]-1,agent_location[1])\n",
    "            num_steps += 1\n",
    "        if (action == \"east\"):\n",
    "            agent_location = (agent_location[0],agent_location[1]+1)\n",
    "            num_steps += 1\n",
    "        if (action == \"west\"):\n",
    "            agent_location = (agent_location[0],agent_location[1]-1)\n",
    "            num_steps += 1\n",
    "        if (action == \"south\"):\n",
    "            agent_location = (agent_location[0]+1,agent_location[1])\n",
    "            num_steps += 1\n",
    "\n",
    "        if (action == \"suck\"):\n",
    "            num_dirty = num_dirty - 1\n",
    "            num_steps += 1 \n",
    "            grid[agent_location[0], agent_location[1]] = 0\n",
    "\n",
    "        if num_dirty == 0:\n",
    "            break\n",
    "\n",
    "    if verbose == True:\n",
    "        print(grid)\n",
    "    return num_dirty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size</th>\n",
       "      <th>Simple Randomized Agent</th>\n",
       "      <th>Simple Reflex Agent</th>\n",
       "      <th>Model Based Reflex Agent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5x5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10x10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100x100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1996.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Size  Simple Randomized Agent  Simple Reflex Agent  \\\n",
       "0      5x5                      0.0                  0.0   \n",
       "1    10x10                      0.0                  0.0   \n",
       "2  100x100                      0.0                  6.0   \n",
       "\n",
       "   Model Based Reflex Agent  \n",
       "0                       2.0  \n",
       "1                      16.0  \n",
       "2                    1996.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simulating with new environment while returning how many spots were left dirty\n",
    "\n",
    "# making table\n",
    "df = pd.DataFrame({\n",
    "    \"Size\": [\"5x5\", \"10x10\", \"100x100\"],\n",
    "    \"Simple Randomized Agent\": np.zeros(3),\n",
    "    \"Simple Reflex Agent\": np.zeros(3),\n",
    "    \"Model Based Reflex Agent\": np.zeros(3)\n",
    "})\n",
    "\n",
    "# testing for each size\n",
    "#for one_size in all_size:\n",
    "for one_size in all_size:\n",
    "    simple_randomized_data = []\n",
    "    simple_reflex_data = []\n",
    "    model_based_reflex_data = []\n",
    "    \n",
    "    for i in range(1):\n",
    "        simple_randomized_data.append(obstacle_environment_dirty(simple_randomized_agent, max_steps = 10000000, size = one_size, verbose = False))\n",
    "        simple_reflex_data.append(obstacle_environment_dirty(simple_reflex_agent, max_steps = 1000000, size = one_size, verbose = False))\n",
    "\n",
    "        reached_corner = False \n",
    "        last_move = \"north\" \n",
    "        model_based_reflex_data.append(obstacle_environment_dirty(model_based_reflex_agent, max_steps = 100000, size = one_size, verbose = False))\n",
    "\n",
    "    # adding to table\n",
    "    df.loc[df[\"Size\"] == str(one_size)+\"x\"+str(one_size), \"Simple Randomized Agent\"] = np.mean(simple_randomized_data)\n",
    "    df.loc[df[\"Size\"] == str(one_size)+\"x\"+str(one_size), \"Simple Reflex Agent\"] = np.mean(simple_reflex_data)\n",
    "    df.loc[df[\"Size\"] == str(one_size)+\"x\"+str(one_size), \"Model Based Reflex Agent\"] = np.mean(model_based_reflex_data)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eugty1MF_soc"
   },
   "source": [
    "## More advanced implementation tasks\n",
    "\n",
    "* __Agent for and environment with obstacles:__ Implement an agent for an environment where the agent does not know how large the environment is (we assume it is rectangular), where it starts or where the obstacles are. An option would be to always move to the closest unchecked/uncleaned square (note that this is actualy depth-first search).\n",
    "\n",
    "* __Utility-based agent:__ Change the environment for a $5 \\times 5$ room, so each square has a fixed probability of getting dirty again. For the implementation, we give the environment a 2-dimensional array of probabilities. The utility of a state is defined as the number of currebntly clean squares in the room. Implement a utility-based agent that maximizes the expected utility over one full charge which lasts for 100000 time steps. To do this, the agent needs to learn the probabilities with which different squares get dirty again. This is very tricky!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "qjjIU8Dj_sod"
   },
   "outputs": [],
   "source": [
    "# Your ideas/code"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
